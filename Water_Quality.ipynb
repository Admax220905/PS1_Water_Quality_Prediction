# Water Quality Classification - Repaired Code
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (precision_score, recall_score, 
                           accuracy_score, f1_score, confusion_matrix)
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os

# Create output directory
os.makedirs('output', exist_ok=True)

# 1. Data Loading and Preparation
def load_data():
    data = pd.read_csv('Data.csv')
    if 'Unnamed: 0' in data.columns:
        data = data.drop(columns=['Unnamed: 0'])
    data = data.dropna()
    return data

# 2. Data Analysis
def analyze_data(data):
    print("Missing Values:\n", data.isnull().sum())
    print("\nClass Distribution:\n", data['Label'].value_counts(normalize=True))
    return data[['Chloride', 'Organic_Carbon', 'Solids', 'Sulphate', 'Turbidity', 'ph']], data['Label']

# 3. Model Training
def train_models(X_train, y_train):
    models = {
        'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),
        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced'),
        'SVM': SVC(random_state=42, probability=True, class_weight='balanced'),
        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)
    }
    
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        results[name] = {'Model': model}
        print(f"{name} trained successfully.")
    return models, results

# 4. Model Evaluation
def evaluate_models(models, X_test, y_test):
    results = {}
    for name, model in models.items():
        y_pred = model.predict(X_test)
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        results[name] = {
            'Precision': precision_score(y_test, y_pred),
            'Recall': recall_score(y_test, y_pred),
            'Accuracy': accuracy_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred),
            'Sensitivity': recall_score(y_test, y_pred),  # Same as recall
            'Specificity': tn / (tn + fp),
            'Confusion Matrix': cm,
            'Model': model
        }
    return results

# 5. Visualization
def visualize_results(results, X_columns):
    # Confusion Matrices
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('Confusion Matrices', fontsize=16)
    axes = axes.ravel()
    for idx, (name, metrics) in enumerate(results.items()):
        sns.heatmap(metrics['Confusion Matrix'], annot=True, fmt='d', 
                    cmap='Blues', ax=axes[idx], cbar=False)
        axes[idx].set_title(name)
    plt.tight_layout()
    plt.savefig('output/confusion_matrices.png', dpi=300)
    plt.close()
    
    # Feature Importance (Random Forest only)
    rf_model = results['Random Forest']['Model']
    importances = pd.Series(rf_model.feature_importances_, index=X_columns)
    plt.figure(figsize=(10, 6))
    importances.sort_values().plot(kind='barh', color='skyblue')
    plt.title('Feature Importance (Random Forest)')
    plt.savefig('output/feature_importance.png', bbox_inches='tight')
    plt.close()

# Main Execution
if __name__ == "__main__":
    # Load and prepare data
    data = load_data()
    X, y = analyze_data(data)
    
    # Split and scale data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    joblib.dump(scaler, 'output/scaler.pkl')
    
    # Train and evaluate models
    models, results = train_models(X_train_scaled, y_train)
    results = evaluate_models(models, X_test_scaled, y_test)
    
    # Save best model
    best_model_name = max(results, key=lambda x: results[x]['F1-Score'])
    joblib.dump(results[best_model_name]['Model'], 
               f'output/best_model_{best_model_name.replace(" ", "_")}.pkl')
    
    # Generate visualizations
    visualize_results(results, X.columns)
    
    # Print results
    print("\nFinal Metrics:")
    for name, metrics in results.items():
        print(f"\n{name}:")
        for metric, value in metrics.items():
            if metric != 'Model' and metric != 'Confusion Matrix':
                print(f"{metric}: {value:.4f}")

print("Execution completed successfully!")
